---
title: "Likelihood of Being Diagnosed with Heart Disease"
author: "Daniel Evans"
date: "1st of November 2020"
output:
  html_document: default
  pdf_document: default
subtitle: Analysis of Categorical Data Course Project - Phase II
linkcolor: blue
---

\newpage

\tableofcontents

\newpage

# 1. Introduction \label{sec1}

Carrying on from phase one, this report aims to fit a logistic regression model to determine the likelihood of being diagnosed with heart disease based on a number of independent variables. A saturated logistic regression model was first fit to the data to determine which variables were significant in predicting heart disease. An analysis of variance was conducted to determine this. A reduced logistic regression model was then fit to the data using only the significant variables found. Residual analysis was then conducted to examine the assumption of homoscedasticity and to observe the accuracy of the model. A response analysis on the effects of blood pressure and diagnosis of heart disease showed that as blood pressure increased, the probability of being diagnose with heart disease also increased. The goodness of fit values indicated that both models fitted the data reasonably well. The likelihood of not being diagnosed with heart disease with a blood pressure 70 was found to be 0.77 with a 95% confidence Wald interval of 0.59 < pi < 0.88. A hypothesis test of the model parameters was then conducted to check for significance. Odds ratios found that for every one unit increase in resting blood pressure, the odds of being diagnosed with heart disease increases by 0.93, for every ten unit increase in resting blood pressure, the odds of being diagnosed with heart disease increases by 1.18, and having 4 blood vessels coloured by fluoroscopy compared with 3 increases the odds of being diagnosed with heart diseases by 48 times. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 2. Statistical Modelling

For the purpose of the logistic regression model, the categorical variables were converted to factors. 

```{r}
library(car)
heart <- read.csv("Project Group 62_data.csv")

heart$sex <- as.factor(heart$sex)
heart$cp <- as.factor(heart$cp)
heart$fbs <- as.factor(heart$fbs)
heart$restecg <- as.factor(heart$restecg)
heart$exang <- as.factor(heart$exang)
heart$slope <- as.factor(heart$slope)
heart$ca <- as.factor(heart$ca)
heart$thal <- as.factor(heart$thal)
heart$target <- as.factor(heart$target)
```

## 2.1 Model Fitting

Firstly, a saturated logistic model was fitted using all of the independent variables to determine which ones were relevant for predicting heart disease. 

### Full Model

```{r}
mod.fit <- glm(formula = target ~ ., family = binomial(link = logit),
               data = heart)
summary(mod.fit)
Anova(mod.fit)
```

The analysis of variance of the saturated model indicates that sex, type of chest pain (cp), resting blood pressure (trestbps), slope of the peak during exercise (slope), number of major vessels coloured by fluoroscopy (ca), and whether or not someone had a heart defect (thal) are all good predictors of heart disease as their p values all fall below 0.05. 

### Reduced Model

The reduced model was then fitted using the relevant variables found from the analysis of variance of the saturated model. 

```{r}
sex <- heart$sex
chestPain <- heart$cp
bloodPressure <- heart$trestbps
slopeExercise <- heart$slope
numberBloodVessels <- heart$ca
heartDefect <- heart$thal
target <- heart$target

reducedModel <- glm(target ~ sex + chestPain + bloodPressure + slopeExercise
                    + numberBloodVessels + heartDefect, 
                    family = binomial(link = logit))
summary(reducedModel)
Anova(reducedModel)
coef(reducedModel)
```

The summary() function found that certain levels of categorical variable were statistically significant and others not. This can be seen in the case of the number of blood vessels coloured by fluoroscopy which is significant for levels 1, 2, and 3 however 4 does not appear to be significant to the model. Contrary to this, the analysis of variance indicates that all of the independent variables in the model are significant. 

### Final Model

Logit(Probability of Heart Disease) = 2.33 – 1.67 x Sex 1 + 1.55 x Chest Pain 1  + 2.41 x Chest Pain 2 + 2.39 x Chest Pain 3 – 0.03 x Blood Pressure – 0.47 x Slope Exercise 1  + 1.86 x Slope Exercise 2 – 2.78 x Blood Vessels 1 – 3.21 x Blood Vessels 2 – 2.33 x Blood Vessels 3  + 1.54 x Blood Vessels 4 + 2.44 x Heart Defect 1 + 2.41 x Heart Defect 2 + 0.81 x Heart Defect 3

## 2.2 Residual Analysis

```{r}
reducedModel.stdres = rstandard(reducedModel)

hist(reducedModel.stdres, freq = FALSE, 
     main = "Histogram of Standardised Residuals",
     xlab = "Standardised Residuals")
curve(dnorm(x), add=TRUE, col = "blue")

plot(bloodPressure, reducedModel.stdres,
     ylab = "Standardised Residuals",
     xlab = "Blood Pressure")
abline(h = c(0,0), col = "red")
```

The histogram of standardised residuals is normally distributed with most of the values falling close to 0 which indicates the model is working well. There are a few values which have errors greater than 3 standard deviations which is something to note. 

The assumption of homoscedasticity of residuals for blood pressure appears to be true as the variance appears to be constant. Most of the errors fall close to zero however there are a few which fall greater than 3 standard deviations. 

## 2.3 Response Analysis

```{r}
heart <- read.csv("Project Group 62_data.csv")

w <-aggregate(formula = target ~ trestbps, data = heart,
             FUN = sum)
n<-aggregate(formula = target ~ trestbps, data = heart,
               FUN = length)

trestbps.fit <- glm(formula = target ~ trestbps, data = heart, 
               family = binomial(link = logit))

plot(x = w$trestbps, y = w$target/n$target, 
     xlab="Blood Pressure",
     ylab="Estimated probability", panel.first =
       grid(col = "gray", lty = "dotted"))
curve(expr = predict(object = trestbps.fit, newdata =
    data.frame(trestbps = x), type = "response"), n = 303, col =
        "red", add = TRUE)
```
I was intrigued at analysing the effect of blood pressure on the probability of being diagnosed with heart disease. One would expect that the higher the blood pressure, the greater chance of being diagnosed with heart disease. To examine the effects of Blood Pressure alone, a model was fit with that independent variable only. The above response analysis indicates the original hypothesis to be true. One must remember that in this dataset, a target value of 0 indicates diagnosis of heart disease so as this plot shows, as the blood pressure increases, values tend toward 0. A logistic regression cure was fitted however it appears more as a straight line as there instances where patients with low blood pressure are diagnosed with heart disease and vice versa. 

## 2.4 Goodness of Fit

```{r}
reducedModel.rdev <- reducedModel$deviance
reduced.dfr <- reducedModel$df.residual
reducedModel.fit <- reducedModel.rdev/reduced.dfr

fullModel.rdev <- mod.fit$deviance
fullModel.dfr <- mod.fit$df.residual
fullModel.fit <- fullModel.rdev/fullModel.dfr

Models <- c("Reduced", "Full")
Res.dev <- c(reducedModel.rdev, fullModel.rdev)
df <- c(reduced.dfr, fullModel.dfr)
fit <- c(reducedModel.fit, fullModel.fit)
good.fit.data <- data.frame(Models, Res.dev, df, fit, stringsAsFactors=FALSE)
good.fit.data

```
Both the full and reduced models appear to be relatively good fits for the data with goodness of fit values greater than 0.6. The reduced model performs slightly better than the saturated model (0.68 > 0.64)

## 2.5 Confidence Intervals

```{r}
# Predicting likelihood of not having heart dieases with a blood pressure of 70
predict.data<-data.frame(trestbps = 70)
predict(object = trestbps.fit, newdata = predict.data, type =
            "link")
predict(object = trestbps.fit, newdata = predict.data, type =
            "response")

alpha<-0.05
linear.pred<-predict(object = trestbps.fit, newdata =
                       predict.data, type = "link", se = TRUE)
pi.hat<-exp(linear.pred$fit) / (1 + exp(linear.pred$fit))
CI.lin.pred<-linear.pred$fit + qnorm(p = c(alpha/2, 1-alpha/2))*linear.pred$se
CI.pi<-exp(CI.lin.pred)/(1+exp(CI.lin.pred))
data.frame(predict.data, pi.hat, lower = CI.pi[1],
                 upper = CI.pi[2])
```

I decided to predict the likelihood of not being diagnosed with heart disease with a blood pressure of 70. The logistic regression model found that with a blood pressure of 70, the probability of not begin diagnosed with heart disease was 0.77. the 95% Wald confidence interval for this prediction was 0.59 < pi < 0.88. Thus, the probability of not being diagnosed with heart disease with a blood pressure as low as 70 is quite high. 

## 2.6 Hypothesis Tests for Regression Parameters

```{r}
summary(reducedModel)
# Likelihood Ratio Test (LRT)
Anova(reducedModel)
```
The hypothesis test indicates that there is sufficient evidence to suggest that sex, type of chest pain (cp), resting blood pressure (trestbps), slope of the peak during exercise (slope), number of major vessels coloured by fluoroscopy (ca), and whether or not someone had a heart defect (thal) all have an effect on the diagnosis of heart disease as their respective p values are all below the alpha significance level of 0.05. The remaining variables in the data were deemed to be insignificant from the hypothesis test. 

## 2.7 Sensitivity Analysis

```{r}
# Every 1mm/HG increase in resting blood pressure
exp(trestbps.fit$coefficients[2])

# Every 10mm/HG increase in resting blood pressure
1/exp(10*trestbps.fit$coefficients[2])

# Wald confidence interval for odds ratio
beta.ci<-confint.default(object = trestbps.fit, parm = "trestbps", level = 0.95)
rev(1/exp(beta.ci*10)) #Invert OR C.I. with c=10

# Having 4 blood vessels colour by flouroscopy vs 3
exp(reducedModel$coefficients[12] - reducedModel$coefficients[11])
```

The above results can be interpreted as follows:

- For every one unit increase in resting blood pressure, the odds of being diagnosed with heart disease increases by 0.93.
- For every ten unit increase in resting blood pressure, the odds of being diagnosed with heart disease increases by 1.18
- Having 4 blood vessels coloured by fluoroscopy compared with 3 increases the odds of being diagnosed with heart diseases by 48 times. 

# 3. Critique and Limitations

This analysis assumed linearity between the dependent variable and the independent variables. It also assumed that there was no multicollinearity between the independent variables. Further analysis should conduct a covariance matrix between the independent variables to check for multicollinearity. A limitation of this study is the amount of data. With only 303 instances, we cannot be sure of the results determined. A greater number of instances might provide further evidence to what we have concluded in this analysis. A strength of this study is the reliability of the data. The data was collected at a medical centre with reliable instruments providing reliability and confidence in the data that was collect. 


# 4. Summary and Conclusions

This analysis showed that there is a relationship between sex, type of chest pain (cp), resting blood pressure (trestbps), slope of the peak during exercise (slope), number of major vessels coloured by fluoroscopy (ca), and whether or not someone had a heart defect (thal) on the diagnosis of heart disease. Phase one of the project prepared the data for analysis and found that gender, age, and maximum heart rate during exercise could be good predictors for Heart Disease in the logistic regression model. 

In relation to the original goal, we were able to determine the probability of a patient being diagnosed or not diagnosed with heart disease based on certain attribute information. We were also able to analyse the effects of varying levels of significant predictor variables and how these effect the odds of being diagnosed with heart disease. This is what the analysis was originally set out to achieve. By understanding what contributes to heart disease and how changes to personal health increase the odds of being diagnosed with heart disease, we can better educate and treat people against Australia’s leading cause of death. 

